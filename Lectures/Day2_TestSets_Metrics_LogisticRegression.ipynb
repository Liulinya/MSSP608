{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Day2-TestSets-Metrics-LogisticRegression.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chetan-parthiban/MSSP608/blob/master/Lectures/Day2_TestSets_Metrics_LogisticRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dGUsekIP1TQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.formula.api as smf\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "from matplotlib import dates\n",
        "from datetime import datetime\n",
        "import calendar\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, cohen_kappa_score, confusion_matrix, ConfusionMatrixDisplay, f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import train_test_split, KFold"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-nnWJXXnr-f",
        "colab_type": "text"
      },
      "source": [
        "# Prerequisites (What you should know from Day 1)\n",
        "\n",
        "Here's what you should understand well from day 1 to be able to understand this notebook. If you don't feel comfortable with any of these topics its HIGHLY recommended that you review it before continuing with this notebook!\n",
        "\n",
        "- Preprocessing the data with pandas\n",
        "- What are decision trees\n",
        "- How to train a decision tree in scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jfzos_3nR3-F",
        "colab_type": "text"
      },
      "source": [
        "# Downloading and Preprocessing the Data (Same as in Day 1)\n",
        "\n",
        "If you understand this part of the Day 1 notebook, then feel free to skip over reading this part of the notebook since it is exactly the same. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrIzmeDLSDfR",
        "colab_type": "code",
        "outputId": "56fdb190-7e19-498d-a620-c9608249d4d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Download the data\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=0B5qTk6DHjanhY2ZaOENiUnROQVZld1lQVXNVNzh0dnZodFdJ' -O bikeshare_train.csv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-17 18:30:07--  https://docs.google.com/uc?export=download&id=0B5qTk6DHjanhY2ZaOENiUnROQVZld1lQVXNVNzh0dnZodFdJ\n",
            "Resolving docs.google.com (docs.google.com)... 172.217.203.113, 172.217.203.139, 172.217.203.102, ...\n",
            "Connecting to docs.google.com (docs.google.com)|172.217.203.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-0s-5c-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/plidd4ugea02ilnn8olmcmsa4pknu9cg/1579284000000/09819396713149841370/*/0B5qTk6DHjanhY2ZaOENiUnROQVZld1lQVXNVNzh0dnZodFdJ?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2020-01-17 18:30:08--  https://doc-0s-5c-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/plidd4ugea02ilnn8olmcmsa4pknu9cg/1579284000000/09819396713149841370/*/0B5qTk6DHjanhY2ZaOENiUnROQVZld1lQVXNVNzh0dnZodFdJ?e=download\n",
            "Resolving doc-0s-5c-docs.googleusercontent.com (doc-0s-5c-docs.googleusercontent.com)... 172.217.203.132, 2607:f8b0:400c:c07::84\n",
            "Connecting to doc-0s-5c-docs.googleusercontent.com (doc-0s-5c-docs.googleusercontent.com)|172.217.203.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 648353 (633K) [text/csv]\n",
            "Saving to: ‘bikeshare_train.csv’\n",
            "\n",
            "bikeshare_train.csv 100%[===================>] 633.16K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2020-01-17 18:30:08 (128 MB/s) - ‘bikeshare_train.csv’ saved [648353/648353]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFc_Fr7wP1Td",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the data with pandas and properly setup the date/time data\n",
        "bikeshare = pd.read_csv(\"bikeshare_train.csv\")\n",
        "bikeshare[\"date_objs\"] = bikeshare[\"datetime\"].apply(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MT0M5uPOP1Tj",
        "colab_type": "code",
        "outputId": "9fe95a7a-f387-457c-8ab0-2126f30a4192",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Create columns for different parts of the date/time data\n",
        "bikeshare[\"hour\"] = bikeshare[\"date_objs\"].apply(lambda x: x.hour)\n",
        "bikeshare[\"day\"] = bikeshare[\"date_objs\"].apply(lambda x: x.day)\n",
        "bikeshare[\"month\"] = bikeshare[\"date_objs\"].apply(lambda x: x.month)\n",
        "bikeshare[\"year\"] = bikeshare[\"date_objs\"].apply(lambda x: x.year)\n",
        "bikeshare[\"weekday\"] = bikeshare[\"date_objs\"].apply(lambda x: x.weekday())\n",
        "bikeshare[\"plot_time\"] = bikeshare[\"datetime\"].apply(dates.datestr2num)\n",
        "\n",
        "bikeshare[\"month_str\"] = bikeshare[\"month\"].apply(lambda x: calendar.month_name[x])\n",
        "bikeshare[\"weekday_str\"] = bikeshare[\"weekday\"].apply(lambda x: calendar.day_name[x])\n",
        "\n",
        "# Create column to tell to represent the traffic ammount \n",
        "bikeshare[\"high_traffic\"] = bikeshare[\"count\"] > 145\n",
        "\n",
        "# Create columns for the weather data\n",
        "def weather_norm(x):\n",
        "    if x == 1:\n",
        "        return \"clear\"\n",
        "    if x == 2:\n",
        "        return \"overcast\"\n",
        "    if x > 2:\n",
        "        return \"gross\"\n",
        "    \n",
        "bikeshare[\"weather_norm\"] = bikeshare[\"weather\"].apply(weather_norm)\n",
        "\n",
        "# Check the distribution of the weather data and preview the dataframe\n",
        "print(bikeshare[\"weather_norm\"].value_counts())\n",
        "bikeshare.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "clear       7192\n",
            "overcast    2834\n",
            "gross        860\n",
            "Name: weather_norm, dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>datetime</th>\n",
              "      <th>season</th>\n",
              "      <th>holiday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>weather</th>\n",
              "      <th>temp</th>\n",
              "      <th>atemp</th>\n",
              "      <th>humidity</th>\n",
              "      <th>windspeed</th>\n",
              "      <th>casual</th>\n",
              "      <th>registered</th>\n",
              "      <th>count</th>\n",
              "      <th>date_objs</th>\n",
              "      <th>hour</th>\n",
              "      <th>day</th>\n",
              "      <th>month</th>\n",
              "      <th>year</th>\n",
              "      <th>weekday</th>\n",
              "      <th>plot_time</th>\n",
              "      <th>month_str</th>\n",
              "      <th>weekday_str</th>\n",
              "      <th>high_traffic</th>\n",
              "      <th>weather_norm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2011-01-01 00:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.84</td>\n",
              "      <td>14.395</td>\n",
              "      <td>81</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>16</td>\n",
              "      <td>2011-01-01 00:00:00</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>5</td>\n",
              "      <td>734138.000000</td>\n",
              "      <td>January</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>False</td>\n",
              "      <td>clear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2011-01-01 01:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.02</td>\n",
              "      <td>13.635</td>\n",
              "      <td>80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "      <td>32</td>\n",
              "      <td>40</td>\n",
              "      <td>2011-01-01 01:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>5</td>\n",
              "      <td>734138.041667</td>\n",
              "      <td>January</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>False</td>\n",
              "      <td>clear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2011-01-01 02:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.02</td>\n",
              "      <td>13.635</td>\n",
              "      <td>80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "      <td>27</td>\n",
              "      <td>32</td>\n",
              "      <td>2011-01-01 02:00:00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>5</td>\n",
              "      <td>734138.083333</td>\n",
              "      <td>January</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>False</td>\n",
              "      <td>clear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2011-01-01 03:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.84</td>\n",
              "      <td>14.395</td>\n",
              "      <td>75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>13</td>\n",
              "      <td>2011-01-01 03:00:00</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>5</td>\n",
              "      <td>734138.125000</td>\n",
              "      <td>January</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>False</td>\n",
              "      <td>clear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2011-01-01 04:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.84</td>\n",
              "      <td>14.395</td>\n",
              "      <td>75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2011-01-01 04:00:00</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>5</td>\n",
              "      <td>734138.166667</td>\n",
              "      <td>January</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>False</td>\n",
              "      <td>clear</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              datetime  season  holiday  ...  weekday_str  high_traffic  weather_norm\n",
              "0  2011-01-01 00:00:00       1        0  ...     Saturday         False         clear\n",
              "1  2011-01-01 01:00:00       1        0  ...     Saturday         False         clear\n",
              "2  2011-01-01 02:00:00       1        0  ...     Saturday         False         clear\n",
              "3  2011-01-01 03:00:00       1        0  ...     Saturday         False         clear\n",
              "4  2011-01-01 04:00:00       1        0  ...     Saturday         False         clear\n",
              "\n",
              "[5 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjzEnlHSSrJx",
        "colab_type": "text"
      },
      "source": [
        "# Train/Test Splits\n",
        "\n",
        "Setting data into different groups for training and testing is a very important part of the data sciene workflow. Many of the models we use can easily fit the data set they are trained on perfectly, but this usually results in nonsensical models that are \"overfitted\" to the data and cannot generalize to any other new  data points. This makes them basically useless. Setting aside some data for testing allows us to simulate this change and perform better evaluations of our model. [Check this resource out for more info on train/test splits.](https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocwdyn7VP1Tr",
        "colab_type": "text"
      },
      "source": [
        "## Creating the Train/Test Split\n",
        "\n",
        "Now that we know that using a train/test split is important for properly evaluating our models, let's consider some different ways to potentially create that train/test split. We'll see that we have to be careful when creating our train/test split to make sure that it makes sense. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dv54N-ouXIMV",
        "colab_type": "text"
      },
      "source": [
        "### The most naive split\n",
        "\n",
        "What is the simplest way to create a train/test split? Draw a line at some point in the dataset and take one side to be the train data and the other to be the test data! The following steps detail an easy procedure to do this. \n",
        "1.   Pick a size for the test set (in this case, we will use 20% of the data for the test set)\n",
        "2.   Take the first section of data as the train set\n",
        "3.   Take the second section of data as the test set\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Yw9SrsAP1Ts",
        "colab_type": "code",
        "outputId": "12d05c3b-6e99-4273-ce17-c6b1b01ef584",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Calculate where the cutoff should be if we want 20% of our data to be in the test set\n",
        "test_set_percentage = 0.2\n",
        "test_set_size = int(len(bikeshare)*test_set_percentage) \n",
        "test_cutoff = len(bikeshare) - test_set_size \n",
        "\n",
        "# Take everything before the cutoff to be the train set\n",
        "bikeshare_train = bikeshare[:test_cutoff]\n",
        "\n",
        "# Take everything after the cutoff to be the test set \n",
        "bikeshare_test = bikeshare[test_cutoff:]\n",
        "\n",
        "# Lets check to make sure the size of our train and test data seem about correct\n",
        "print(\"Size of train data:\", len(bikeshare_train))\n",
        "print(\"Size of test  data:\", len(bikeshare_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of train data: 8709\n",
            "Size of test  data: 2177\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEUgllhmP1Ty",
        "colab_type": "text"
      },
      "source": [
        "But doing this split naively can sometimes be a big problem! To see why, lets look at the distribution of the months represented in the train set and the months represented in the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvkAoadoP1T0",
        "colab_type": "code",
        "outputId": "c4ef417f-4894-4b92-ca09-8b682036581e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Training set months:\")\n",
        "print(bikeshare_train[\"month_str\"].value_counts())\n",
        "print('-----------')\n",
        "print(\"Test set months:\")\n",
        "print(bikeshare_test[\"month_str\"].value_counts())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set months:\n",
            "July         912\n",
            "May          912\n",
            "June         912\n",
            "April        909\n",
            "March        901\n",
            "February     901\n",
            "January      884\n",
            "August       558\n",
            "November     456\n",
            "December     456\n",
            "October      455\n",
            "September    453\n",
            "Name: month_str, dtype: int64\n",
            "-----------\n",
            "Test set months:\n",
            "September    456\n",
            "December     456\n",
            "October      456\n",
            "November     455\n",
            "August       354\n",
            "Name: month_str, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6CMilxnP1T7",
        "colab_type": "text"
      },
      "source": [
        "### Improving our sampling method\n",
        "Notice that our test set only contains 5/12 of the months! This means that whenever we run our model, we are only evaluating our model on its performance during these months. What we really want is to evaluate our model on a little bit of data from every month so, clearly, this method is not what we want for this task. \n",
        "\n",
        "So, how can we fix this? Lets think about why the problem is occuring in the first place. The best way to do this is to look at the data!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_ktlMxGdcwM",
        "colab_type": "code",
        "outputId": "f8a4af8d-64c2-4557-dcdc-2a02eab9522d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "bikeshare.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>datetime</th>\n",
              "      <th>season</th>\n",
              "      <th>holiday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>weather</th>\n",
              "      <th>temp</th>\n",
              "      <th>atemp</th>\n",
              "      <th>humidity</th>\n",
              "      <th>windspeed</th>\n",
              "      <th>casual</th>\n",
              "      <th>registered</th>\n",
              "      <th>count</th>\n",
              "      <th>date_objs</th>\n",
              "      <th>hour</th>\n",
              "      <th>day</th>\n",
              "      <th>month</th>\n",
              "      <th>year</th>\n",
              "      <th>weekday</th>\n",
              "      <th>plot_time</th>\n",
              "      <th>month_str</th>\n",
              "      <th>weekday_str</th>\n",
              "      <th>high_traffic</th>\n",
              "      <th>weather_norm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2011-01-01 00:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.84</td>\n",
              "      <td>14.395</td>\n",
              "      <td>81</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>16</td>\n",
              "      <td>2011-01-01 00:00:00</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>5</td>\n",
              "      <td>734138.000000</td>\n",
              "      <td>January</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>False</td>\n",
              "      <td>clear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2011-01-01 01:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.02</td>\n",
              "      <td>13.635</td>\n",
              "      <td>80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "      <td>32</td>\n",
              "      <td>40</td>\n",
              "      <td>2011-01-01 01:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>5</td>\n",
              "      <td>734138.041667</td>\n",
              "      <td>January</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>False</td>\n",
              "      <td>clear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2011-01-01 02:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.02</td>\n",
              "      <td>13.635</td>\n",
              "      <td>80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "      <td>27</td>\n",
              "      <td>32</td>\n",
              "      <td>2011-01-01 02:00:00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>5</td>\n",
              "      <td>734138.083333</td>\n",
              "      <td>January</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>False</td>\n",
              "      <td>clear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2011-01-01 03:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.84</td>\n",
              "      <td>14.395</td>\n",
              "      <td>75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>13</td>\n",
              "      <td>2011-01-01 03:00:00</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>5</td>\n",
              "      <td>734138.125000</td>\n",
              "      <td>January</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>False</td>\n",
              "      <td>clear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2011-01-01 04:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9.84</td>\n",
              "      <td>14.395</td>\n",
              "      <td>75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2011-01-01 04:00:00</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>5</td>\n",
              "      <td>734138.166667</td>\n",
              "      <td>January</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>False</td>\n",
              "      <td>clear</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              datetime  season  holiday  ...  weekday_str  high_traffic  weather_norm\n",
              "0  2011-01-01 00:00:00       1        0  ...     Saturday         False         clear\n",
              "1  2011-01-01 01:00:00       1        0  ...     Saturday         False         clear\n",
              "2  2011-01-01 02:00:00       1        0  ...     Saturday         False         clear\n",
              "3  2011-01-01 03:00:00       1        0  ...     Saturday         False         clear\n",
              "4  2011-01-01 04:00:00       1        0  ...     Saturday         False         clear\n",
              "\n",
              "[5 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKuyROlndhpa",
        "colab_type": "text"
      },
      "source": [
        "If we look at the data, we can quickly realize that the data points are sorted by their date/time! This means that when we are taking the last 20% of the data, we are actually taking the data from the last 20% of dates/times and this is why we only see a few of the months appear in our current test set!\n",
        "\n",
        "Lets come up with a different way to sample our test data that avoids this problem. An easy way to do this if we want 20% of our data in the test set is to through the data in order and for every 5 data points, we set the first 1 to be test data and the last 4 to be train data. Visually, we can compare the two sampling methods in the following way:\n",
        "\n",
        "Simplest method: OOOOOOOOOOOOXXX\n",
        "\n",
        "Improved method: OOOOXOOOOXOOOOX\n",
        "\n",
        "Now lets try implementing this in code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJuuF13aP1T9",
        "colab_type": "code",
        "outputId": "c135cfc5-eac8-4901-9a73-ac51be250cdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Calculate how often to send data to the test set (in our case for an 80/20 train/test split)\n",
        "test_size = 0.2\n",
        "test_modulus = int(1/test_size)\n",
        "\n",
        "# Set 4/5 data points from each set of 5 data points to be in the train set\n",
        "bikeshare_train = bikeshare.iloc[bikeshare.index % test_modulus != 0]\n",
        "# Set the remaining 1 data point from each set of 5 data points to be in the test set\n",
        "bikeshare_test = bikeshare.iloc[bikeshare.index % test_modulus == 0]\n",
        "\n",
        "# Lets confirm the size of the train and test set are still about right\n",
        "print(\"Size of train data:\", len(bikeshare_train))\n",
        "print(\"Size of test  data:\", len(bikeshare_test))\n",
        "\n",
        "# Lets examine the distribution of the months in the two datasets\n",
        "print(\"Training set months:\")\n",
        "print(bikeshare_train[\"month_str\"].value_counts())\n",
        "print(\"Test set months:\")\n",
        "print(bikeshare_test[\"month_str\"].value_counts())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of train data: 8708\n",
            "Size of test  data: 2178\n",
            "Training set months:\n",
            "May          730\n",
            "August       730\n",
            "July         729\n",
            "June         729\n",
            "December     729\n",
            "October      729\n",
            "September    728\n",
            "November     728\n",
            "April        727\n",
            "March        721\n",
            "February     721\n",
            "January      707\n",
            "Name: month_str, dtype: int64\n",
            "Test set months:\n",
            "December     183\n",
            "July         183\n",
            "November     183\n",
            "June         183\n",
            "August       182\n",
            "May          182\n",
            "April        182\n",
            "October      182\n",
            "September    181\n",
            "February     180\n",
            "March        180\n",
            "January      177\n",
            "Name: month_str, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pe5oIwknc48R",
        "colab_type": "text"
      },
      "source": [
        "Notice how now our train and test datasets now have the same distribution of months! If we didn't look at the data, it would seem like these two methods are essentially identical and interchangable. This example shows us that sometimes a very simple modification can make a big difference and why its important to be careful when making our train/test split. \n",
        "\n",
        "Now, it might seem like we can always use this second method we have developed and like it will always be better than the first method. In practice, this turns out to be very false. For example, if we had taken 1 out of every 12 data points to be in our test set, our test set would be entirely data points from noon and midnight, with no other times represented! It is important to think about your data carefully before making a decision on how to do your train/test split! Here are some resources to learn more about this problem:\n",
        "\n",
        "- [The story of a bad train/test split](https://anotherdatum.com/train-test.html)\n",
        "- [Random Test/Train Splits is Not Always Enough](http://www.win-vector.com/blog/2015/01/random-testtrain-split-is-not-always-enough/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yx8avvDtP1UC",
        "colab_type": "text"
      },
      "source": [
        "## Comparing models with Train/Test Splits\n",
        "\n",
        "Lets see how we can use the train/test split we created to better understand and compare different models. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5M0pQJpqAWI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create lists of possible features (Same as in Day 1)\n",
        "date_features = [\"day\", \"month_str\", \"year\", \"weekday_str\", \"season\", \"holiday\", \"workingday\"]\n",
        "time_features = [\"hour\"]\n",
        "weather_features = [\"weather\", \"temp\", \"atemp\", \"humidity\", \"windspeed\"]\n",
        "\n",
        "feature_sets = {\n",
        "    \"date\": date_features,\n",
        "    \"time\": time_features,\n",
        "    \"date + time\": date_features + time_features,\n",
        "    \"weather\": weather_features,\n",
        "    \"all\": date_features + time_features + weather_features\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "nuB1Z1NqP1UF",
        "colab_type": "code",
        "outputId": "19416b74-1986-4d6a-ae97-c9e9896c76a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# We'll keep track of which classifier was the best\n",
        "best = 0\n",
        "best_name = None\n",
        "best_actual = None\n",
        "best_predictions = None\n",
        "\n",
        "test_accuracies = []\n",
        "train_accuracies = []\n",
        "\n",
        "# For each feature set, we evaluate our model on both the train and the test set\n",
        "for set_name, feature_set in feature_sets.items():\n",
        "\n",
        "    # Create a dummyset with only the features in our feature set\n",
        "    X = bikeshare.loc[:, feature_set]\n",
        "    X = pd.get_dummies(X)\n",
        "\n",
        "    y = bikeshare[\"high_traffic\"]\n",
        "\n",
        "    # Use scikit-learn to create our train/test split and train our decision tree\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.20, random_state=123)\n",
        "    model = DecisionTreeClassifier(criterion=\"entropy\", random_state=123).fit(X_train, y_train)\n",
        "\n",
        "    # Calculate our accuracy on the train and test sets\n",
        "    train_pred = model.predict(X_train)\n",
        "    train_accuracy = 100*accuracy_score(y_train, train_pred)\n",
        "    test_pred = model.predict(X_test)\n",
        "    test_accuracy = 100*accuracy_score(y_test, test_pred)\n",
        "\n",
        "    # Keep track of the best model on the test set\n",
        "    if test_accuracy > best:\n",
        "        best = test_accuracy\n",
        "        best_name = set_name\n",
        "        best_actual = y_test\n",
        "        best_predictions = test_pred\n",
        "    test_accuracies.append(test_accuracy)\n",
        "    train_accuracies.append(train_accuracy)\n",
        "\n",
        "    # Display the accuracy on the train and test set for each model\n",
        "    print(f\"Results for {set_name}:\")\n",
        "    print(f\"Accuracy on the train set: {train_accuracy:.1f}\")\n",
        "    print(f\"Accuracy on the test set: {test_accuracy:.1f}\")\n",
        "    print(\"------------------------\")\n",
        "    \n",
        "print(f\"Best feature set is: {best_name} \\nWith: {best:.1f}% accuracy.\")    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for date:\n",
            "Accuracy on the train set: 66.4\n",
            "Accuracy on the test set: 62.6\n",
            "------------------------\n",
            "Results for time:\n",
            "Accuracy on the train set: 81.0\n",
            "Accuracy on the test set: 80.1\n",
            "------------------------\n",
            "Results for date + time:\n",
            "Accuracy on the train set: 100.0\n",
            "Accuracy on the test set: 90.8\n",
            "------------------------\n",
            "Results for weather:\n",
            "Accuracy on the train set: 90.7\n",
            "Accuracy on the test set: 68.5\n",
            "------------------------\n",
            "Results for all:\n",
            "Accuracy on the train set: 100.0\n",
            "Accuracy on the test set: 90.7\n",
            "------------------------\n",
            "Best feature set is: date + time \n",
            "With: 90.8% accuracy.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "3rBROZYuP1UL",
        "colab_type": "code",
        "outputId": "66c5071f-207e-499b-8891-e78806256e2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "locs = np.arange(len(test_accuracies))\n",
        "\n",
        "ax = plt.gca()\n",
        "ax.bar(locs-0.2, train_accuracies, width=0.4)\n",
        "ax.bar(locs+0.2, test_accuracies, width=0.4)\n",
        "ax.set_xticks(locs)\n",
        "ax.set_xticklabels(list(feature_sets.keys()))\n",
        "ax.legend([\"Train Accuracy\", \"Test Accuracy\"])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hg5ZZ4zthbn",
        "colab_type": "text"
      },
      "source": [
        "If we had just looked at the train set, we would have thought that using date and time alone we could perfectly model the levels of bikeshare traffic. Once we look at the test accuracy, we realize that that is not true at all! While 90% accuracy is pretty great, that 10% of misclassified data demonstrates that our model is definitely not perfect. \n",
        "\n",
        "We can also see that the model trained on just date/time is actually better than the model trained on date/time/weather! This is an example of more data not always being better and an example of how our decision tree algorithm does not always converge to the optimal tree, just a pretty good one!\n",
        "\n",
        "Here are some more resources diving further into comparing models using train/test splits and the convergence of decision trees:\n",
        "\n",
        "- [Train/Test Splits and Cross Validation in Python](https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6)\n",
        "- [Disadvantages of Decision Trees (this article is pretty technical)](https://www.edupristine.com/blog/decision-trees-development-and-scoring)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9KIukwvP1UQ",
        "colab_type": "text"
      },
      "source": [
        "# Metrics of Model Quality\n",
        "\n",
        "While accuracy is great some of the time, there are many cases where it is not a good metric for understanding the performance of our models. Lets explore some alternate methods for evaluating our models and figure out when we should be using them. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQjfddI-zMoJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lets keep the predictions from the best tree that we found to use in this section\n",
        "predictions = best_predictions\n",
        "actual = np.array(list(best_actual))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjbrVmTsP1UW",
        "colab_type": "text"
      },
      "source": [
        "### Accuracy\n",
        "\n",
        "$$ accuracy = \\frac{correct \\space predictions}{total \\space predictions} \\times 100 $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XO8JyuwvP1UY",
        "colab_type": "code",
        "outputId": "26c50688-9551-4849-ef3b-7200f20a3c04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Calculating accuracy manually\n",
        "matches = (predictions == actual).sum() \n",
        "accuracy = matches / len(actual)\n",
        "print(f\"Manual accuracy metric: {100*accuracy:.1f}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Manual accuracy metric: 90.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Bq3FRJA2ghY",
        "colab_type": "code",
        "outputId": "cc8100aa-58e2-47c4-d5f6-734beeac7f20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Calculating accuracy with scikit-learn\n",
        "accuracy = accuracy_score(actual, predictions)\n",
        "print(f\"scikit-learn accuracy metric: {100*accuracy:.1f}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "scikit-learn accuracy metric: 90.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkSqyL94yVME",
        "colab_type": "text"
      },
      "source": [
        "#### Pros/Cons the accuracy metric\n",
        "\n",
        "**Benefit**\n",
        "- Accuracy is very intuitive and easy to understand\n",
        "\n",
        "**Weakness**\n",
        "- Accuracy can sometimes paint an inaccurate picture of the model. For example, consider a model that predicts whether or not there will be an earthquake in LA today. You could get >99% accuracy by just guessing no every time, so accuracy can be very misleading in this case!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qzDpWovP1Uc",
        "colab_type": "text"
      },
      "source": [
        "### Confusion Matrix\n",
        "\n",
        "The confusion matrix is a great way to visualize where our model is making errors. Elements on the diagonal represent correct predictions. Elements off the diagonal represent that the model predicted the wrong class.\n",
        "\n",
        "![Example Confusion Matrix](https://www.mathworks.com/help/examples/nnet/win64/CreateConfusionMatrixChartExample_02.png)\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGC_guSsP1Ue",
        "colab_type": "code",
        "outputId": "ecbd8c0d-4691-40d7-853a-99e833e5f40f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Generating our confusion matrix manually\n",
        "\n",
        "# Helper function to display our confusion matrix nicely\n",
        "def matrix_print(matrix):\n",
        "    print(\"           Predictions\")\n",
        "    print(f\"Actual    |\", end='')\n",
        "    for pred in list(matrix.keys()):\n",
        "        print(f\"{str(pred).rjust(10)}|\", end='')\n",
        "    print()\n",
        "    for act in list(matrix.keys()):\n",
        "        print(f\"{str(act).rjust(10)}|\", end='')\n",
        "        for pred in list(matrix.keys()):\n",
        "            cell = matrix[pred][act]\n",
        "            print(f\"{str(cell).rjust(10)}|\", end='')\n",
        "        print()\n",
        "\n",
        "# Actually computing our confusion matrix         \n",
        "def build_confusion_matrix(actual, predictions):\n",
        "    confusion_matrix = {}\n",
        "    for pred_value in np.unique(predictions):\n",
        "        confusion_matrix[pred_value] = {}\n",
        "        for act_value in np.unique(actual):\n",
        "            cell_count = 0\n",
        "            for i in range(len(actual)):\n",
        "                if predictions[i] == pred_value and actual[i] == act_value:\n",
        "                    cell_count += 1\n",
        "            confusion_matrix[pred_value][act_value] = cell_count\n",
        "    return confusion_matrix\n",
        "\n",
        "conf_matrix = build_confusion_matrix(actual, predictions)\n",
        "matrix_print(conf_matrix)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "           Predictions\n",
            "Actual    |     False|      True|\n",
            "     False|       976|        97|\n",
            "      True|       103|      1002|\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4p0misf3Blo",
        "colab_type": "code",
        "outputId": "eee6c361-5032-4f98-ae98-b68e8c024063",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Generating our confusion matrix with scikit-learn\n",
        "conf_matrix = confusion_matrix(actual, predictions)\n",
        "ConfusionMatrixDisplay(conf_matrix, [\"low traffic\", \"high traffic\"]).plot(values_format='.4g')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW8AAAEKCAYAAADdBdT9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJ2y9AnqzzGI",
        "colab_type": "text"
      },
      "source": [
        "#### Pros/Cons of the confusion matrix\n",
        "\n",
        "**Benefit**\n",
        "- Gives us a deeper understanding of our model performance than accuracy alone\n",
        "\n",
        "**Weakness**\n",
        "- We don't get a single number out so it is hard to tell which model is \"better\" when comparing two models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Auzth_5JP1Uj",
        "colab_type": "text"
      },
      "source": [
        "### Cohen's Kappa\n",
        "\n",
        "$$ \\kappa = \\frac{accuracy - chance \\space agreement}{1 - chance \\space agreement}$$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkCyuEgrP1Uk",
        "colab_type": "code",
        "outputId": "bc48743a-32a8-4c2d-b933-95bd61207da1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Calculating Kappa Manually\n",
        "matching_by_chance = 0\n",
        "for label in np.unique(actual):\n",
        "    predicted_probability = (predictions == label).sum() / len(predictions)\n",
        "    actual_probability = (actual == label).sum() / len(actual)\n",
        "    matching_by_chance += (predicted_probability * actual_probability)\n",
        "\n",
        "print(f\"Probability of matching by chance: {matching_by_chance:.3f}\")\n",
        "kappa = (accuracy - matching_by_chance) / (1 - matching_by_chance)\n",
        "print(f\"Manual kappa metric: {kappa:.3f}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Probability of matching by chance: 0.500\n",
            "Manual kappa metric: 0.816\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKOYL5VT9i3g",
        "colab_type": "code",
        "outputId": "d9a3f032-31f1-4f53-dcfc-adc4dc3163ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Calculating Kappa with scikit-learn\n",
        "kappa = cohen_kappa_score(actual, predictions)\n",
        "print(f\"scikit-learn kappa metric: {kappa:.3f}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "scikit-learn kappa metric: 0.816\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rml2sD4e99c0",
        "colab_type": "text"
      },
      "source": [
        "#### Pros/Cons of Cohen's Kappa\n",
        "\n",
        "**Benefit**\n",
        "- Gives us a single number that evaluates the accuracy of our model and compares it to a simple baseline model -- guessing randomly based on the distribution of the data\n",
        "\n",
        "**Weakness**\n",
        "- What threshold denotes a \"good\" kappa value is highly subjective"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Trf8kb9JP1Up",
        "colab_type": "text"
      },
      "source": [
        "### Precision, Recall, and F-Score\n",
        "\n",
        "$$ Precision = \\frac{sucessful \\space predictions}{predicted \\space positives}$$\n",
        "$$ Recall = \\frac{sucessful \\space predictions}{actual \\space positives}$$\n",
        "$$ F \\mbox{-} score = \\frac{2 \\times precision \\times recall}{precision + recall}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "QQ58yjrsP1Uw",
        "colab_type": "code",
        "outputId": "bbecb943-5e1d-4812-e6f1-df9a1c40bf3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Compute Precision, Recall, and F-Score Manually\n",
        "# Compute number of predictions, number of correct predictions, and number of total positives\n",
        "predicted_positives = (predictions == True).sum()\n",
        "actual_positives = (actual == True).sum()\n",
        "successful_predictions = 0\n",
        "for i in range(len(predictions)):\n",
        "    if predictions[i] == True and actual[i] == True:\n",
        "        successful_predictions += 1\n",
        "\n",
        "# Compute Precision Manually\n",
        "precision = successful_predictions / predicted_positives\n",
        "print(f\"Precision: {precision:.3f}\")\n",
        "\n",
        "# Compute Recall Manually\n",
        "recall = successful_predictions / actual_positives\n",
        "print(f\"Recall: {recall:.3f}\")\n",
        "\n",
        "#Compute F-Score Manually\n",
        "f = (2*precision*recall)/(precision + recall)\n",
        "print(f\"F-Score: {f:.3f}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision: 0.912\n",
            "Recall: 0.907\n",
            "F-Score: 0.909\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RabGO8IbP1U0",
        "colab_type": "code",
        "outputId": "5a3e5dbb-2f6f-4b08-ecab-2f1e73199ae2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Compute Precision, Recall, and F-Score with a Confusion Matrix\n",
        "conf_matrix = build_confusion_matrix(actual, predictions)\n",
        "\n",
        "successful_positives = conf_matrix[True][True]\n",
        "predicted_positives = 0\n",
        "for a in conf_matrix[True].keys():\n",
        "    predicted_positives += conf_matrix[True][a]\n",
        "\n",
        "precision = successful_positives / predicted_positives\n",
        "print(f\"Precision: {precision:.3f}\")\n",
        "\n",
        "actual_positives = 0\n",
        "for p in conf_matrix.keys():\n",
        "    actual_positives += conf_matrix[p][True]\n",
        "    \n",
        "recall = successful_positives / actual_positives\n",
        "print(f\"Recall: {recall:.3f}\")\n",
        "\n",
        "f = (2*precision*recall)/(precision + recall)\n",
        "\n",
        "print(f\"F-Score: {f:.3f}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision: 0.912\n",
            "Recall: 0.907\n",
            "F-Score: 0.909\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJT27o2dCROO",
        "colab_type": "code",
        "outputId": "653cb825-187e-496b-f1b6-b68230aed4f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Compute Precision, Recall, and F-Score with scikit-learn\n",
        "precision = precision_score(actual, predictions)\n",
        "recall = recall_score(actual, predictions)\n",
        "f = f1_score(actual, predictions)\n",
        "\n",
        "print(f\"Precision: {precision:.3f}\")\n",
        "print(f\"Recall: {recall:.3f}\")\n",
        "print(f\"F-Score: {f:.3f}\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision: 0.912\n",
            "Recall: 0.907\n",
            "F-Score: 0.909\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8xHX1LxDtVf",
        "colab_type": "text"
      },
      "source": [
        "#### Pros/Cons of F-score\n",
        "\n",
        "**Benefit**\n",
        "- Achieves a balance between precision and recall without sacrificing much of either\n",
        "\n",
        "**Weakness**\n",
        "- It is hard to interpret, and is not as useful when we care about one of the two components more than the other\n",
        "\n",
        "**High precision is important when...**\n",
        "- You are working with limited resources and can’t say yes often\n",
        "- The stakes for making a mistake are very high\n",
        "\n",
        "**High recall is important when...**\n",
        "- It is not very expensive or hard to say yes to everything\n",
        "- The cost of missing out is greater than the cost of making a mistake"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8fkR4TaP1U5",
        "colab_type": "text"
      },
      "source": [
        "### Additional metric calculation\n",
        "\n",
        "There are many other metrics that could be used to compare models. Here are a few more:\n",
        "\n",
        "$$ specificity = \\frac{successful \\space negatives}{actual \\space negatives}$$\n",
        "\n",
        "$$ sensitivity = \\frac{successful \\space positives}{actual \\space positives} = recall $$\n",
        "\n",
        "$$ false \\space positive \\space rate = \\frac{false \\space positives}{predicted \\space positives}$$\n",
        "\n",
        "$$ false \\space negative \\space rate = \\frac{false \\space negatives}{predicted \\space negatives}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuQ_Ox6qP1U6",
        "colab_type": "code",
        "outputId": "101776f8-896c-43c6-e2bb-9c5d5142d86c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "conf_matrix = build_confusion_matrix(actual, predictions)\n",
        "\n",
        "# Specificity\n",
        "successful_negatives = conf_matrix[False][False]\n",
        "actual_negatives = 0\n",
        "for p in conf_matrix.keys():\n",
        "    actual_negatives += conf_matrix[p][False]\n",
        "specificity = successful_negatives / actual_negatives\n",
        "print(f\"Specificity: {specificity:.3f}\")\n",
        "\n",
        "# Sensitivity\n",
        "actual_positives = 0\n",
        "for p in conf_matrix.keys():\n",
        "    actual_positives += conf_matrix[p][True]\n",
        "\n",
        "sensitivity = successful_positives / actual_positives\n",
        "print(f\"Sensitivity: {sensitivity:.3f}\")\n",
        "\n",
        "# False Positive Rate\n",
        "false_positives = conf_matrix[True][False]\n",
        "predicted_positives = 0\n",
        "for a in conf_matrix[True].keys():\n",
        "    predicted_positives += conf_matrix[True][a]\n",
        "fpr = false_positives / predicted_positives\n",
        "print(f\"False Positive Rate: {fpr:.3f}\")\n",
        "\n",
        "# False Negative Rate\n",
        "false_negatives = conf_matrix[False][True]\n",
        "predicted_negatives = 0\n",
        "for a in conf_matrix[False].keys():\n",
        "    predicted_negatives += conf_matrix[False][a]\n",
        "fnr = false_negatives / predicted_negatives\n",
        "print(f\"False Negative Rate: {fnr:.3f}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Specificity: 0.910\n",
            "Sensitivity: 0.907\n",
            "False Positive Rate: 0.088\n",
            "False Negative Rate: 0.095\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-jwJxaUIxqm",
        "colab_type": "text"
      },
      "source": [
        "#### Pros/Cons of these metrics\n",
        "\n",
        "**Benefit**\n",
        "- In some use cases, certain results have much bigger impacts than other. For example, in a self-driving car, we'd much rather have a false positive detection of a human in front of the car than a false negative. In the case of a false positive, the car detects a human who isn't there and slows down which is fine, but in a false negative the car does not detect a human that is there and runs them over. For these sorts of high sensitivity use cases, these metrics can be very important. \n",
        "\n",
        "**Weakness**\n",
        "- Each of these metrics only paints a partial picture of our model's performance as they are highly specialized"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BD0nOkdOP1U-",
        "colab_type": "text"
      },
      "source": [
        "### Using metrics to compare models\n",
        "Now let's group everything together, all in a single loop, using scikit-learn's built-in calculations for several of the above metrics and compare our models. Notice how the scikit-learn functions for each of the metrics takes in the same inputs in the same order. This allows us to easily interchange functions whenever we want and is one of the truly beautiful parts of scikit-learn's design!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GemZ2MtDKRgY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "date_features = [\"day\", \"month_str\", \"year\", \"weekday_str\", \"season\", \"holiday\", \"workingday\"]\n",
        "time_features = [\"hour\"]\n",
        "weather_features = [\"weather\", \"temp\", \"atemp\", \"humidity\", \"windspeed\"]\n",
        "\n",
        "feature_sets = {\n",
        "    \"date\": date_features,\n",
        "    \"time\": time_features,\n",
        "    \"date + time\": date_features + time_features,\n",
        "    \"weather\": weather_features,\n",
        "    \"all\": date_features + time_features + weather_features\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4NJl3VQP1VA",
        "colab_type": "code",
        "outputId": "37334ae3-0208-4af9-fcfa-64406bc56f27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "best = 0\n",
        "best_name = None\n",
        "\n",
        "precisions = []\n",
        "recalls = []\n",
        "kappas = []\n",
        "accuracies = []\n",
        "\n",
        "predictions = {}\n",
        "actual = None\n",
        "\n",
        "for set_name, feature_set in feature_sets.items():\n",
        "\n",
        "    X = bikeshare.loc[:, feature_set]\n",
        "    X = pd.get_dummies(X)\n",
        "\n",
        "    y = bikeshare[\"high_traffic\"]\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.20, random_state=123)\n",
        "\n",
        "    model = DecisionTreeClassifier(criterion=\"entropy\", random_state=123).fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    accuracy = 100*accuracy_score(y_test, y_pred)\n",
        "    kappa = cohen_kappa_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    \n",
        "    metric_to_optimize = accuracy\n",
        "    \n",
        "    if metric_to_optimize > best:\n",
        "        best = metric_to_optimize\n",
        "        best_name = set_name\n",
        "        \n",
        "    predictions[set_name] = y_pred\n",
        "    actual = np.array(list(y_test))\n",
        "    \n",
        "    # Bookkeeping and printing for the reader (not part of the core loop)\n",
        "    print(f\"Results for {set_name}:\")\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "    print(f\"Accuracy: {accuracy:.1f} Kappa: {kappa:.3f} Precision: {precision:.3f} Recall: {recall:.3f}\")\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    kappas.append(kappa)\n",
        "    accuracies.append(accuracy)\n",
        "    print(\"------------------------\")\n",
        "    \n",
        "print(f\"Best feature set is: {best_name} \\nWith: {best:.1f}% accuracy.\")    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for date:\n",
            "[[572 501]\n",
            " [314 791]]\n",
            "Accuracy: 62.6 Kappa: 0.250 Precision: 0.612 Recall: 0.716\n",
            "------------------------\n",
            "Results for time:\n",
            "[[ 717  356]\n",
            " [  78 1027]]\n",
            "Accuracy: 80.1 Kappa: 0.600 Precision: 0.743 Recall: 0.929\n",
            "------------------------\n",
            "Results for date + time:\n",
            "[[ 976   97]\n",
            " [ 103 1002]]\n",
            "Accuracy: 90.8 Kappa: 0.816 Precision: 0.912 Recall: 0.907\n",
            "------------------------\n",
            "Results for weather:\n",
            "[[780 293]\n",
            " [392 713]]\n",
            "Accuracy: 68.5 Kappa: 0.372 Precision: 0.709 Recall: 0.645\n",
            "------------------------\n",
            "Results for all:\n",
            "[[ 962  111]\n",
            " [  91 1014]]\n",
            "Accuracy: 90.7 Kappa: 0.814 Precision: 0.901 Recall: 0.918\n",
            "------------------------\n",
            "Best feature set is: date + time \n",
            "With: 90.8% accuracy.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgM-tTgxL9LX",
        "colab_type": "text"
      },
      "source": [
        "Notice how even though our \"best\" feature set results in a model that performs better for most metrics, it is still worse than some of the other models in recall. Its up to you as the scientist to determine what metrics are most important for a good model in your context!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H90v266oP1VE",
        "colab_type": "text"
      },
      "source": [
        "#### Results by Feature Set\n",
        "\n",
        "With the loop above, we're able to quickly see the following results:\n",
        "\n",
        "| Date | Time | Weather | Accuracy  |\n",
        "|------|------|---------|-----------|\n",
        "| X    |      |         | 61.3%     |\n",
        "|      | X    |         | 81.7%     |\n",
        "|      |      | X       | 66.9%     |\n",
        "| X    | X    |         | 90.8%     |\n",
        "| X    | X    | X       | **91.2%** |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsZbeieRP1VH",
        "colab_type": "text"
      },
      "source": [
        "### Visualizing model comparisons\n",
        "We can use plots to visually see the differing performances of our models on two metrics at the same time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "wzQ-3qAdP1VJ",
        "colab_type": "code",
        "outputId": "892c7965-fb98-4d73-a3cb-c42ecbaf9917",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Set up plot\n",
        "plt.xlim(0.5,1)\n",
        "plt.xlabel(\"Precision\")\n",
        "plt.ylim(0.5,1)\n",
        "plt.ylabel(\"Recall\")\n",
        "plt.title(\"Recall vs Precision for Different Feature Sets\")\n",
        "\n",
        "# Plot data\n",
        "names = list(feature_sets.keys())\n",
        "for i in range(len(precisions)):\n",
        "    x = precisions[i]\n",
        "    y = recalls[i]\n",
        "    plt.scatter(x, y)\n",
        "    plt.text(x+.01, y+.01, names[i], fontsize=9)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3de3QV9b338fcXAkJRQQQFiVIxCEJr\nRVLQipJARRElQqliD1X6iJcutYq1VYqHgqtUezwPKkf7eLzVW4FDtVCoglolYAEPhMqlYKFIVe6g\nEloQSIDv88dMwjYkk53LZO+Ez2utLPZc93d+zJ7P3PZsc3dEREQq0ijVBYiISHpTUIiISCQFhYiI\nRFJQiIhIJAWFiIhEUlCIiEgkBUU9YmY5ZrYpofsjM/t2KmuqDWZ2sZmtTWK8n5nZMzHV8Asz+9TM\ntsUx/wrec46Z3VBRDWY2xMw2mtkeM+tRV3WJlKWgqKZwI70v/BBvM7Pnzez4VNdVm8JgOhwu47/M\nbK2Z/aC238fd33X3LkmM90t3H1Xb729mZwA/Brq5e7tamqeb2d6w7T4zs7fN7NrEcdx9oLu/EFHD\nfwK3u/vx7v5+bdRVhfrHm9nLlYyT+Bko+Tuthu/7pZ2humBmmWb2ahjSu83sr2Y2Mslp882s1tfJ\ndKOgqJmr3P144DygBzAmxfXEYUu4jCcC9wJPm1m3siOZWUadV1Z7zgA+c/cdVZ2wkuX+Rth2XYDn\ngcfN7OdVqKEjsLqqNSVRV226Kgyykr8tdfS+5armcr8EbCRo75OB7wPba7Oues/d9VeNP+Aj4NsJ\n3f8BvJbQfRzBHuEnBCvdk0DzhOF5wHLgn8CHwOVh/x8AHwD/AjYAtyRMkwNsqqiGhP69gW1A44R+\nQ4CV4eteQEH43tuBSRUs45feL+y3ExgGfBVw4MZwGReEwy8AFgGFwAogJ2Ha1sBvgC3ALmBmBct1\nL7A5bIO1QP+w/3jg5YTxBhNsSAuBfOCcMm1zD7AS2A38D9CsnGX8NrAPOAzsAZ5Pct73hvM+AGSU\nM18Hssr0GwbsB04Ou/OBUeXUMDX814G9wIfh+KcBr4b/B/8AfpQw7/HAK8DL4f/rKIIdwfsI1q/P\ngOlA63D8kv+/G8L/v0+BseGwy4EioDisY0Uyn4Eyw6LWg3LXcaBFmXbYEy7z88AvKvkcfOn/I6qt\nyql1D3BexPBylwWYCBwK/0/3AI8DBjwC7Aj/H1YBX0v19qqmfykvoL7+JX5IgMxwhXgsYfgjwCyC\njeMJwGzgwXBYL4KN16Xhh7kD0DUcNgg4K1zh+gJfAOeHw8r7gFT0Qf0QuDSh+3fAfeHrxcD3w9fH\nAxdUMI/S9wvrHBJuPLpwZEPzYvgBbx4ux2fAFeH4l4bdbcN5vEawwT4JaAL0Led9uhDs3Z0Wdn8V\nOCt8PZ4wKICzCTail4bz+imwHmia0DZLCDYYrQk2TLdWtpxVmPdy4HQSwr/MPMsLiibAQWBg2J0P\njCqvhrLzCNtzGTAOaAp0ItjIXpbQNsXA1eG4zYE7gfcI1s/jgP8Gpia0qwNPh+N+g2Aje07Ztk7m\nM1Cmf2XrQdLreNjveSoPitL/j8raqpx6/wQsBIYDZ1RxWUr/D8Puy8L3bhUu3zlA+1Rvr2r6p1NP\nNTPTzP5FsGHbAfwcwMwMuBkY7e6fu/u/gF8SrIgQ7IU/5+5vufthd9/s7n8DcPfX3P1DD8wH3gQu\nrkZtU4HrwnpOIFjRp4bDioEsM2vj7nvc/b2I+ZxmZoUEe5w/JwiYxAvP4919r7vvA0YAr7v76+Fy\nvUVw5HKFmbUHBhJsrHe5e3G4fGUdItiodTOzJu7+kbt/WM541xIcwb3l7sUER2/NgW8ljDPZ3be4\n++cEQX1exHJWZ94bw+VOSjivTwmCq6q+SbBxesDdi9x9A8FGfnjCOIvdfWbY9vuAWwmOEja5+wGC\njf+wMqdnJrj7PndfQbC3/I0q1jXTzArDv5lhvwrXA6jVdTxR4v9HMm2V6LvAu8C/A/8ws+Vm9s1k\nlqUcxQQ7hl0Bc/cP3H1rDZct5RQUNXO1u59AsIfTFWgT9m8LfAVYVvIhAuaG/SHY8ylv44eZDTSz\n98zs83C6KxLmWxVTgKFmdhwwFPiLu38cDruRYK/5b2a21MyujJjPFndv5e6t3f08d59WZvjGhNcd\nge8mbDgKgT5Ae4Jl/tzdd0UV7e7rgbsINmo7zGxaBRdITwM+TpjucFhLh4RxEu9g+oLg6CkZycx7\nY9mJKmNmTQjWgc+rOi1B255Wpm1/BpwaUVNHYEbC+B8QBHHiNNVtoxJXh+tHK3e/OuF9K1oPanMd\nT1R2PaysrUqFOy73uXv3cJzlBAFolS1LOfN6h+AU1BME6+9TZnZiDZct5RQUtSDcK3qeYM8Tgr3G\nfUD3hA9RSw8ubEKwUp9Vdj7hRv3VcD6nunsr4HWCQ9iq1rSGYGM3EPgeQXCUDPu7u18HnAL8CnjF\nzFpU9T1KZpfweiPwUsIyt3L3Fu7+UDistZm1SqL2Ke7eh+BD6mGNZW0JhwOlR3GnE1zbqKlk5l2d\nxy7nEZx6WlKNaTcC/yjTtie4e+KebdmaNhKc5kqcppm7J9NGNXmsdIXrQRLreHnvu5dgx6tEeXem\nlV0PK2urcrn7p2FtJacso9bpcut198nu3hPoRrBD9pPK3jfdKShqz6PApWb2jXAP9GngETM7BcDM\nOpjZZeG4zwI/MLP+ZtYoHNaV4HzqcQQX4A6a2UBgQA1qmkJwnvoSgmsUhLWMMLO2YZ2FYe/DNXif\nEi8DV5nZZWbW2Myahbc7ZoaH33OAX5vZSWbWxMwuKTsDM+tiZv3CDcp+jlzcLGs6MChswyYEt5Ye\nILjoWFO1Om8za21m/0awl/krd/+sGrNZAvzLzO41s+Zh+34t4RRJeZ4EJppZx7COtmaWl+T7bQe+\nambV2UZUuB5Q+Tq+HTjZzFom9FtOcPqytZm1IzjijFKltjKzX4XDM8LTtD8E1of/T1HLUlJvp4R5\nfdPMeofrzV6Cdbg2PlsppaCoJe6+k+DC7riw170EF0DfM7N/Elww6xKOu4Tgzo9HCC5qzwc6enAt\n40cEG6pdBEcCs2pQ1lSCi4XvhHtKJS4HVpvZHuAxYHhVzrVXxN03Euw1/4xgQ7CRYG+qZD37PsE5\n3L8RXNMp7wN/HPAQwVHZNoKjnqNuOw6vk4wA/isc9yqCWzWLamE5amveK8I2Xk9wF9Jodx9XyTQV\n1XQIuJLgOss/wrqeAVpGTPYYwfrzZngt7T2CO+KSUbJj8ZmZ/aWKtVa4HlS2jntwrW4qsCE81XMa\nwe2rKwguWr9JcENE1PtXta2+Aswg2GnaQHA0ObiyZQmnfYzgus8uM5tMcBv50+GyfUxw4fvhqHrr\nA3PXDxeJiEjFdEQhIiKRYgsKM3vOzHaY2V8rGG5mNtnM1pvZSjM7P65aRESk+uI8onie4Fx4RQYC\nncO/m4H/F2MtIiJSTbEFhbsvIPp+8TzgxfBLN+8BrSz4UpaIiKSRVD7IrQNf/pLMprDfUd9iNLOb\nCY46aNGiRc+uXbvWSYEiIg3FsmXLPnX3tpWPebR68cRPd38KeAogOzvbCwoKUlyRiEj9YmYfVz5W\n+VJ519Nmgm+7lsikdr5VKyIitSiVQTELuD68++kCYHdDeHiWiEhDE9upJzObSvCwvDYW/GLVzwke\ns4y7P0nwfJcrCL61+gXBN5VFRCTNxBYU4UPnooY7cFtc7y8iIrVD38wWEZFICgoREYmkoBARkUgK\nChERiaSgEBGRSAoKERGJpKAQEZFICgoREYmkoBARkUgKChERiaSgEBGRSAoKERGJpKAQEZFICgoR\nEYmkoBARkUgKCpFaVlhYyIsvvgjA888/z1tvvZXiikRqRkEhUssSg2LkyJFceumlKa5IpGZi+4U7\nkWPVpEmTWLZsGTk5Oezdu5c777yTESNGkJWVxZAhQ/jzn/9Mz549ad++PW+88QYnnXQSM2fOxMwY\nM2YMixYtoqioiLFjx3LllVemenFEdEQhUtvuvvtuevbsSX5+PoMGDSrtf/DgQb7//e+zePFi3n77\nbc455xwWLFiAmbF8+XLmzp3Lrl27mD9/Pm+//TZjx44l+MVgkdTSEYVIHcnIyODcc88FoEOHDvTo\n0QOAzMxMPv/8c1atWsX8+fPJyckB4MCBA3z22We0adMmVSWLADqiEKl1TZs25eDBg5WOZ2alr92d\n7t27M2DAAPLz88nPz2flypUKiRQYOXIkf/7znwHIyspKcTXpQUcUIrWsXbt2NG/enO985zvs2LEj\n6Y3NFVdcwaJFi8jJycHMyMzM5KWXXoq5WpHKKShEqmrldHj7Adi9CVpmQv9xcO41pYMbNWrEnDlz\njpps/fr1pa//9Kc/lb5+/PHHS1//4he/iKloKc+nn37Ktddey6FDhyguLuY3v/lNqktKSwoKkapY\nOR1m/wiK9wXduzcG3fClsJD6oWXLlsyZM4emTZsyZ84cHnrooVSXlJZ0jUKkKt5+4EhIlCjeF/SX\neqewsJARI0ZwySWXMGHCBDZu3FjueJWdPpw8eXIc5bF8+XIWLFhQ2n3XXXexc+fOWN4rioJCpCp2\nb6paf0lrL7/8Mj169GDBggWMGzeu2rcjVzco8vPzGT9+fIXDywbFo48+Stu2bav1XjWhoBCpipaZ\nVesvaW3AgAFMmzaNgQMH8s4775T2P3z4MCNGjGDz5s2MHj26tP+8efPIzc3l4osvJi8vj/379zNl\nyhQ2b95MTk4OEydOpLi4mFGjRpGbm0ufPn1YsmRJteubNGkSzz77LDk5OaXvsWnTJj766CN69uzJ\niBEj+NrXvsbTTz/NDTfcwPnnn8+DDz4IwO7du7nmmmvo378//fr1AziuunXoGoVIVfQf9+VrFABN\nmgf9Ja2s+99tLP7Dh+z5/ADHtz6OC/PO4uze7b40Tvfu3VmxYsVR086YMYMWLVqwb98+Fi5cyIwZ\nMwDo1asX8+bNA+Dee+9l+vTpXH/99YwbN478/HwAnnzySbKysnjmmWfYvn07Q4cOZeHChdVahrvv\nvptNmzZx//33HzVs27ZtLFy4kMLCQjp27MjHH39MmzZt6NKlC2PGjOHBBx9k6NChDB8+nBUrVnDe\need1qFYRKChEqqbkgnXEXU+Seuv+dxvzfvs3DhYdBmDP5weY99u/ARwVFuVOv24dvXr1AqB3796l\n33lZvXo1999/PwcOHGD79u2ceOKJR027atUqFi1axNy5c4Fgz76sMWPGsHjxYgoLCyksLCQ/P5/m\nzZuXe7dcRbp27UqzZs1o164dmZmZtGsXLFfz5s05dOhQ6Rc4n3zyyZJJqr29V1CIVNW51ygY0tzi\nP3xYGhIlDhYdZvEfPkwqKDp37sxbb73FjTfeyNKlS0uvXUycOJEJEyZw4YUX8tOf/rS0f0ZGBocP\nH6ZRo0Z0796drKys0lNWRUVFR82/5PRQyZcrK7pOEfXlzcQvbCa+hiNf4LzwwgsZMmRIyTh/r3TB\nK6BrFCLS4Oz5/ECV+peVl5fH7t276du3LzNmzCAjI9inHj58ODfeeCNDhgxhx44dpeMPGzaMQYMG\nMXnyZG666SbWrl1Lbm4uubm5jB07ttrLcdFFF/Hmm28ybNgwtm3bVqVpx44dy/Tp0+nXrx+5ubkA\np1S3DqtvDx3Lzs72goKCVJchImnshZ8tLDcUjm99HDf88qIUVJR6ZrbM3bOrM62OKESkwbkw7ywy\nmn5585bRtBEX5p0FwGsbXmPAKwM494VzGfDKAF7b8Foqyqw3dI1CRBqckusQ5d319NqG1xi/aDz7\nD+0HYOverYxfNB6AQZ0GVTTLY5pOPYnIMWXAKwPYunfrUf3bt2jPm8PeTEFFdSNtTz2Z2eVmttbM\n1pvZfeUM72hmb5vZSjPLNzN9a0lEYrVtb/kXhSvqLzEGhZk1Bp4ABgLdgOvMrFuZ0f4TeNHdzwUe\nAB6Mqx4REYB2Lcq/Pbai/hLvEUUvYL27b3D3ImAakFdmnG5Ayffm55UzXESkVt15/p00a9zsS/2a\nNW7GneffmaKK0l+cQdEBSHwU46awX6IVwNDw9RDgBDM7ueyMzOxmMysws4JUPDlRRBqOQZ0GMf5b\n42nfoj2G0b5Fe8Z/a7wuZEdI9V1P9wCPm9lIYAGwGThUdiR3fwp4CoKL2XVZoIg0PIM6DVIwVEGc\nQbEZOD2hOzPsV8rdtxAeUZjZ8cB33L0wxppERKSK4jz1tBTobGZnmllTYDgwK3EEM2tjZiU1jAGe\ni7EeERGphtiCwt0PArcDbwAfANPdfbWZPWBmg8PRcoC1ZrYOOBWYGFc9IiJSPfrCnYjIMSBtv3An\nIiL1n4JCREQiKShERCSSgkJERCIpKEREJJKCQkREIikoREQkkoJCREQiKShERCSSgkJERCIpKERE\nJJKCQkREIikoREQkkoJCREQiKShERCSSgkJERCIpKEREJJKCQkREIikoREQkkoJCREQiKShERCSS\ngkJERCIpKEREJJKCQkREIikoREQkkoJCREQiKShERCSSgkJERCIpKEREJJKCQkREIikoREQkkoJC\nREQiKShERCSSgkJERCLFGhRmdrmZrTWz9WZ2XznDzzCzeWb2vpmtNLMr4qxHRESqLragMLPGwBPA\nQKAbcJ2ZdSsz2v3AdHfvAQwHfh1XPSIiUj1xHlH0Ata7+wZ3LwKmAXllxnHgxPB1S2BLjPWIiEg1\nxBkUHYCNCd2bwn6JxgMjzGwT8DpwR3kzMrObzazAzAp27twZR60iIlKBVF/Mvg543t0zgSuAl8zs\nqJrc/Sl3z3b37LZt29Z5kSIix7I4g2IzcHpCd2bYL9GNwHQAd18MNAPaxFiTiIhUUZxBsRTobGZn\nmllTgovVs8qM8wnQH8DMziEICp1bEhFJI7EFhbsfBG4H3gA+ILi7abWZPWBmg8PRfgzcZGYrgKnA\nSHf3uGoSEZGqy4hz5u7+OsFF6sR+4xJerwEuirMGERGpmVRfzBYRkTSnoBARkUgKChERiaSgEBGR\nSJEXs83s7qjh7j6pdssREZF0U9ldTyfUSRUiIpK2IoPC3SfUVSEiIpKeKjv1NDlquLv/qHbLERGR\ndFPZqadldVKFiIikrcpOPb1QV4WIiEh6SuoRHmbWFriX4JfqmpX0d/d+MdUlIiJpItnvUfyW4MF+\nZwITgI8Ing4rIiINXLJBcbK7PwsUu/t8d/8/gI4mRESOAck+PbY4/HermQ0i+G3r1vGUJCIi6STZ\noPiFmbUk+P2I/wJOBEbHVpWIiKSNpILC3f8YvtwN5MZXjoiIpJukrlGY2Qtm1iqh+yQzey6+skRE\nJF0kezH7XHcvLOlw911Aj3hKEhGRdJJsUDQys5NKOsysNTH/jKqIiKSHZDf2/xdYbGa/C7u/C0yM\npyQREUknSR1RuPuLwFBge/g31N1firMwqVtZWVkVDps8OfLZkCLSwFXlF+5aA3vd/XFgp5mdGVNN\nkmYUFCLHtmTvevo5wbOexoS9mgAvx1WUxO/w4cOMGDGCvn37Mnp08JWYefPmkZuby8UXX0xeXh77\n9+9nypQpbN68mZycHCZOnEhxcTGjRo0iNzeXPn36sGTJkhQviYjELdkjiiHAYGAvgLtvQb9+V6/9\n4Q9/oEWLFsyfP59hw4Zx8OBBevXqxbx583j33Xfp2rUr06dP53vf+x4dOnQgPz+fsWPH8uyzz5KV\nlcW8efN49dVXS0NGRBquZC9mF7m7m5kDmFmLGGuSOrBu3Tp69eoFQO/evTEzVq9ezf3338+BAwfY\nvn07J5544lHTrVq1ikWLFjF37lwAdu/eXad1i0jdS/aIYrqZ/TfQysxuAv4EPBNfWRK3zp07U1BQ\nAMDSpUtxdyZOnMiECROYP38+gwcPxt0ByMjI4PDhwwB0796d66+/nvz8fPLz8/nLX/6SsmUQkbqR\n7CM8/tPMLgX+CXQBxrn7W7FWJrHKy8vjlVdeoW/fvvTu3ZuMjAyGDx/OjTfeSJcuXWjZsmXpEcWw\nYcMYNGgQAwcO5Ic//CF33HEHubnBk1yys7N5+OGHU7koIhIzK9lrrNJEZo2A69z9t7VfUrTs7Gwv\n2RMWEZHkmNkyd8+uzrSRRxRmdiJwG9ABmAW8FXbfA6wg+EEjSTMz39/Mw2+sZUvhPk5r1ZyfXNaF\nq3t0SHVZIlJPVXbq6SVgF7AYGAX8DDDgandfHnNtUg0z39/MmN+vYl/xIQA2F+5jzO9XASgsRKRa\nKguKTu7+dQAzewbYCpzh7vtjr0yq5eE31paGRIl9xYd4+I21CgoRqZbK7noq+WU73P0QsEkhkd62\nFO6rUn8RkcpUdkTxDTP7Z/jagOZhtwHu7kffaC8pdVqr5mwuJxROa9U8BdWISEMQeUTh7o3d/cTw\n7wR3z0h4rZBIQz+5rAvNmzT+Ur/mTRrzk8u6pKgiEanv9JsSDUzJdQjd9SQitSXWoDCzy4HHgMbA\nM+7+UJnhj3DkN7i/Apzi7q2QGrm6RwcFg4jUmtiCwswaA08AlwKbgKVmNsvd15SM4+6jE8a/A/28\nqohI2qnK71FUVS9gvbtvcPciYBqQFzH+dcDUGOsREZFqiDMoOgAbE7o3hf2OYmYdgTOBdyoYfrOZ\nFZhZwc6dO2u9UBERqVicQVEVw4FXwu9qHMXdn3L3bHfPbtu2bR2XJiJybIszKDYDpyd0Z4b9yjMc\nnXYSEUlLcQbFUqCzmZ1pZk0JwmBW2ZHMrCtwEsHzpEREJM3EFhTufhC4HXgD+ACY7u6rzewBMxuc\nMOpwYJpX53nnIiISu1i/R+HurwOvl+k3rkz3+DhrEBGRmkmXi9kiIpKmFBQiIhJJQSEiIpEUFCIi\nEklBISIikRQUIiISSUEhIiKRFBQiNTRz5kw++eST0u6srKwUViNS+xQUIjVUNiiq69Chcp+JKZJy\nCgo5Zk2YMIEZM2bg7pxyyinMmTOHQ4cOkZ2dzfz58+nbty85OTnceuutuDuffvop/fv3Jycnh4su\nuoh169axZs0a5s6dyx133MF3v/tdAIqKirjlllu44IILuOeeewAoLi5m1KhR5Obm0qdPH5YsWQLA\nyJEjufXWW7nyyit59913U9YWIlH0m9lyzOrXrx/Tp0+nU6dOXHjhhbzzzju0bt2anj17ctddd5Gf\nn0/Lli0ZPXo0r732Gpdddhlz5syhadOmzJkzh4ceeojnnnuOyy+/nFGjRtGnTx8AduzYwYQJEzj1\n1FM555xzGDduHFOmTCErK4tnnnmG7du3M3ToUBYuXAhAx44defLJJ1PZFCKRFBRyzLrgggv48Y9/\nzFlnncXtt9/OY489xrx580oDJC8v+EHGPXv20KVLFwoLC7ntttvYtm0bRUVFnHDCCeXOt0OHDrRr\n1w6AzMxMdu3axapVq1i0aBFz584FYPfu3aXjf+tb34p5SUVqRkEhx6wmTZpw8skn8+qrr3LLLbfw\n8ssv8/vf/57Zs2fTqVMn/vjHP3L88ccDwamjxx9/nB49ejBmzBhef/11Jk2aBEDTpk05ePBg6XzN\n7Evv4+50796drKwsRo8Ofia+qKiodHjjxo3jXlSRGtE1Cjmm9evXj0aNGtG8eXNycnL44osvOPXU\nU5k0aRKDBw8mNzeX/v3788EHHzBgwACmTZvGwIEDeeedI7/ae+WVVzJu3DhuueWWCt/npptuYu3a\nteTm5pKbm8vYsWPrYvFEaoXVt5+ByM7O9oKCglSXISJSr5jZMnfPrs60OqKQBmn37Nn8vV9/Pjin\nG3/v15/ds2enuiSRekvXKKTB2T17Nlv/fRy+fz8AB7dsYeu/B7+X1fKqq1JZmki9pCMKaXB2PPJo\naUiU8P372fHIoymqSKR+U1BIg3Nw69Yq9ReRaAoKaXAy2revUn8RiaagkAbnlNF3Yc2afamfNWvG\nKaPvSlFFIvWbLmZLg1NywXrHI49ycOtWMtq355TRd+lCtkg1KSikQWp51VUKBpFaolNPIiISSUEh\nIiKRFBQiIhJJQSEiIpEUFCIiEklBISIikRQUIiISSUEhIiKRFBQiIhJJQSEiIpEUFCIiEinWoDCz\ny81srZmtN7P7KhjnGjNbY2arzWxKnPWIiEjVxfZQQDNrDDwBXApsApaa2Sx3X5MwTmdgDHCRu+8y\ns1PiqkdERKonziOKXsB6d9/g7kXANCCvzDg3AU+4+y4Ad98RYz0iIlINcQZFB2BjQvemsF+is4Gz\nzWyhmb1nZpeXNyMzu9nMCsysYOfOnTGVKyIi5Un1xewMoDOQA1wHPG1mrcqO5O5PuXu2u2e3bdu2\njksUETm2xRkUm4HTE7ozw36JNgGz3L3Y3f8BrCMIDhERSRNxBsVSoLOZnWlmTYHhwKwy48wkOJrA\nzNoQnIraEGNNIiJSRbEFhbsfBG4H3gA+AKa7+2oze8DMBoejvQF8ZmZrgHnAT9z9s7hqEhGRqjN3\nT3UNVZKdne0FBQWpLkNEpF4xs2Xunl2daVN9MVtERNKcgkJERCIpKEREJJKCQkREIikoREQkkoJC\nREQiKShERCSSgkJERCIpKEREJJKCQkREIikoREQkkoJCREQiKShERCSSgkJERCIpKEREJJKCQkRE\nIikoREQkkoJCREQiKShERCSSgkJERCIpKEREJJKCQkREIikoREQkkoJCREQiKShERCSSgkJERCIp\nKEREJJKCQkREIikoREQkkoJCREQiKShERCSSgkJERCIpKEREJJKCQkREIikoREQkUqxBYWaXm9la\nM1tvZveVM3ykme00s+Xh36g46xERkarLiGvGZtYYeAK4FNgELDWzWe6+psyo/+Put8dVh4iI1Eyc\nRxS9gPXuvsHdi4BpQF6M7yciIjGI7YgC6ABsTOjeBPQuZ7zvmNklwDpgtLtvLDuCmd0M3Bx2HjCz\nv9Z2sfVUG+DTVBeRJtQWR6gtjlBbHNGluhPGGRTJmA1MdfcDZnYL8ALQr+xI7v4U8BSAmRW4e3bd\nlpme1BZHqC2OUFscobY4wswKqjttnKeeNgOnJ3Rnhv1Kuftn7n4g7HwG6BljPSIiUg1xBsVSoLOZ\nnWlmTYHhwKzEEcysfULnYBz9Sm0AAAVySURBVOCDGOsREZFqiO3Uk7sfNLPbgTeAxsBz7r7azB4A\nCtx9FvAjMxsMHAQ+B0YmMeun4qq5HlJbHKG2OEJtcYTa4ohqt4W5e20WIiIiDYy+mS0iIpEUFCIi\nEiltg0KP/ziisrYIx7nGzNaY2Wozm1LXNdaVJNaLRxLWiXVmVpiKOutCEm1xhpnNM7P3zWylmV2R\nijrrQhJt0dHM3g7bId/MMlNRZ9zM7Dkz21HRd80sMDlsp5Vmdn5SM3b3tPsjuPj9IdAJaAqsALqV\nGWck8Hiqa02TtugMvA+cFHafkuq6U9UWZca/g+AmipTXnqL14ingh+HrbsBHqa47hW3xO+CG8HU/\n4KVU1x1TW1wCnA/8tYLhVwBzAAMuAP43mfmm6xGFHv9xRDJtcRPwhLvvAnD3HXVcY12p6npxHTC1\nTiqre8m0hQMnhq9bAlvqsL66lExbdAPeCV/PK2d4g+DuCwjuIK1IHvCiB94DWpX5mkK50jUoynv8\nR4dyxvtOePj0ipmdXs7whiCZtjgbONvMFprZe2Z2eZ1VV7eSXS8ws47AmRzZODQ0ybTFeGCEmW0C\nXic4wmqIkmmLFcDQ8PUQ4AQzO7kOaks3SX+GEqVrUCRjNvBVdz8XeIvg8R/HqgyC0085BHvRT5tZ\nq5RWlHrDgVfc/VCqC0mh64Dn3T2T4JTDS2ZWnz/zNXEP0NfM3gf6Ejwl4lheN6okXVcaPf7jiErb\ngmCvYJa7F7v7PwgesNi5juqrS8m0RYnhNNzTTpBcW9wITAdw98VAM4KH5DU0yWwvtrj7UHfvAYwN\n+zXYGx0iVOUzVCpdg0KP/zii0rYAZhIcTWBmbQhORW2oyyLrSDJtgZl1BU4CFtdxfXUpmbb4BOgP\nYGbnEATFzjqtsm4ks71ok3A0NQZ4ro5rTBezgOvDu58uAHa7+9bKJkr102PL5fE9/qPeSbIt3gAG\nmNkagsPpn7j7Z6mrOh5JtgUEG4ppHt7m0RAl2RY/JjgNOZrgwvbIhtgmSbZFDvCgmTmwALgtZQXH\nyMymEixrm/Da1M+BJgDu/iTBtaorgPXAF8APkppvA1xvRESkFqXrqScREUkTCgoREYmkoBARkUgK\nChERiaSgEBGRSAoKOSaZ2aHwCbN/NbPfmdlXamGe2WY2OWL4aWb2Sk3fR6Su6fZYOSaZ2R53Pz58\n/VtgmbtPShhuBJ+Pw6mqUSRd6IhCBN4Fsszsq+FvGrwI/BU43cwGmNliM/tLeORREi7fNLNFZrbC\nzJaY2QlmlmNmfwyH9034XYz3w+FfLfmdADNrZma/MbNV4fDcsP9IM/u9mc01s7+b2X+kqE1ESiko\n5JhmZhnAQGBV2Ksz8Gt37w7sBe4Hvu3u5wMFwN3hYyL+B7jT3b8BfBvYV2bW9wC3uft5wMXlDL8N\ncHf/OsHD+14ws2bhsPOAa4GvA9c24CcjSz2hoJBjVXMzW06w8f8EeDbs/3H4nH4IftilG7AwHPcG\noCPQBdjq7ksB3P2f7n6wzPwXApPM7EdAq3KG9wFeDqf/G/AxwTO6AN52993uvh9YE76nSMqk5bOe\nROrAvnBvv1RwWYK9ib2At9z9ujLjfb2ymbv7Q2b2GsFzdRaa2WXA/iRrO5Dw+hD6nEqK6YhCpGLv\nAReZWRaAmbUws7OBtUB7M/tm2P+E8BRWKTM7y91XufuvCJ5u2rXMvN8F/i0c92zgjHC+ImlHQSFS\nAXffSfBU4qlmtpLgseVdw5/bvBb4LzNbQfDDWc3KTH5XeOvtSqCY4HeKE/0aaGRmqwiud4xM+H0V\nkbSi22NFRCSSjihERCSSgkJERCIpKEREJJKCQkREIikoREQkkoJCREQiKShERCTS/wdzfCOhS8JC\nKAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aABw1p7QP1VT",
        "colab_type": "code",
        "outputId": "4d183cdd-0be1-42c2-911a-dd05e59086bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Set up plot\n",
        "plt.xlim(0.5,1)\n",
        "plt.xlabel(\"Precision\")\n",
        "plt.ylim(0,1)\n",
        "plt.ylabel(\"Kappa\")\n",
        "plt.title(\"Kappa vs Precision for Different Feature Sets\")\n",
        "\n",
        "# Plot data\n",
        "names = list(feature_sets.keys())\n",
        "for i in range(len(kappas)):\n",
        "    x = precisions[i]\n",
        "    y = kappas[i]\n",
        "    plt.scatter(x, y)\n",
        "    plt.text(x+.01, y+.01, names[i], fontsize=9)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Y6t6odHP1VZ",
        "colab_type": "text"
      },
      "source": [
        "## Statistical significance of differences with a train/test set\n",
        "\n",
        "The following code check, for each pair of models that we have trained, whether or not the models are making significantly different predictions. Here, we are using the [Wilcoxon Signed-Rank Test](https://en.wikipedia.org/wiki/Wilcoxon_signed-rank_test) to get an associated test statistic and p-value for each pair of models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYdIVo1jP1Va",
        "colab_type": "code",
        "outputId": "a0ef2fd2-473d-473f-8c71-d17e395750d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "matches = {}\n",
        "\n",
        "for feature_set in predictions.keys():\n",
        "    boolean_matches = (predictions[feature_set] == actual)\n",
        "    int_matches = [int(x) for x in boolean_matches]\n",
        "    matches[feature_set] = int_matches\n",
        "\n",
        "for set_a in matches.keys():\n",
        "    for set_b in matches.keys():\n",
        "        if set_a != set_b:\n",
        "            matches_a = matches[set_a]\n",
        "            matches_b = matches[set_b]\n",
        "            t, p = stats.wilcoxon(matches_a, matches_b)\n",
        "            print(f\"{set_a} || {set_b}: t={t:.1f}, p={p:.3f}\")\n",
        "    print('------')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "date || time: t=208502.0, p=0.000\n",
            "date || date + time: t=44405.0, p=0.000\n",
            "date || weather: t=170945.0, p=0.000\n",
            "date || all: t=48530.0, p=0.000\n",
            "------\n",
            "time || date: t=208502.0, p=0.000\n",
            "time || date + time: t=23362.5, p=0.000\n",
            "time || weather: t=128527.0, p=0.000\n",
            "time || all: t=21650.0, p=0.000\n",
            "------\n",
            "date + time || date: t=44405.0, p=0.000\n",
            "date + time || time: t=23362.5, p=0.000\n",
            "date + time || weather: t=41170.0, p=0.000\n",
            "date + time || all: t=9554.5, p=0.886\n",
            "------\n",
            "weather || date: t=170945.0, p=0.000\n",
            "weather || time: t=128527.0, p=0.000\n",
            "weather || date + time: t=41170.0, p=0.000\n",
            "weather || all: t=38720.0, p=0.000\n",
            "------\n",
            "all || date: t=48530.0, p=0.000\n",
            "all || time: t=21650.0, p=0.000\n",
            "all || date + time: t=9554.5, p=0.886\n",
            "all || weather: t=38720.0, p=0.000\n",
            "------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xACZQuErXHTd",
        "colab_type": "text"
      },
      "source": [
        "We can see that almost all the pairs of models are pretty different in this cases, indicating that splitting by different features results in models with significantly different predictions! The only two models that don't have significantly different predictions are the models using date/time and date/time/weather, indicating that weather only plays a small role in the model that uses all 3 feature subets!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1hz9rO3P1Vg",
        "colab_type": "text"
      },
      "source": [
        "# Logistic Regression \n",
        "\n",
        "Now that we are starting to get comfortable with decision trees and the basics of machine learnings, lets add a new model to our classification toolkit. Logistic regression is one of the most commonly used machine learning methods in use today. The intuitive idea behind logstic regression is simple -- take our test data and find the line (or plane) that best splits it into the two groups. This is in contrast with decision trees which use a series of if/then statements to split up the data. Logistic regression is very useful when the data has some sort of linear relationship and also comes with the benefit of being easy to interpret. [Here's some more on logistic regression.](https://towardsdatascience.com/logistic-regression-detailed-overview-46c4da4303bc)\n",
        "\n",
        "![alt text](https://miro.medium.com/max/1280/1*bcWJyX3iAIr0MGNIxUnQxg.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qjsu3vnQd34H",
        "colab_type": "text"
      },
      "source": [
        "## Implementation by hand"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4lliDok3ksJ",
        "colab_type": "text"
      },
      "source": [
        "There are a few functions that we must implement in order to train a logistic regression model by hand. Lets consider each part individually, starting with the model itself.\n",
        "\n",
        "The logistic regression model has two essential computational steps. The first is a linear transformation and the second is the logistic function. Intuitively, we can think of the first step as assigning diferent weights (we will call these weights $\\beta$) to each of the data features and taking a weighted average of them all to get a single number to represent the data points. The logistic function then squashes this number between 0 and 1 for us, which turns out to be useful in training. The logistic function looks a bit like this:\n",
        "\n",
        "![alt text](https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/480px-Logistic-curve.svg.png)\n",
        "\n",
        "In equations, a logistic regression model can be expressed as the following:\n",
        "\n",
        "$$ \\hat{y} = \\frac{1}{1 + e^{-X \\beta^T}}$$\n",
        "\n",
        "Lets also implement this in code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HxKeyyqP1Vh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def logistic_regression_model(beta, X): \n",
        "    return 1.0/(1 + np.exp(-np.dot(X, beta.T)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDhJakOpm7de",
        "colab_type": "text"
      },
      "source": [
        "Now that we can evaluate the model for a given input and $\\beta$, we need to consider how to train the model. Many of the techniques used in practice boil down to variants of one core technique -- Gradient Descent. The inuitive idea behind gradient descent is quite simple. First we evaluate our model with some cost function. Then we take the gradients of each of the parameters ($\\beta$s) of our model with respect to the cost function. Finally we move our parameters in the negative direction of the gradient to decrease our cost function. We then repeat this until we converge to a good model. [This resource provides some nice visuals to see what this looks like](https://hackernoon.com/dl03-gradient-descent-719aff91c7d6)\n",
        "\n",
        "![alt text](https://hackernoon.com/hn-images/0*D7zG46WrdKx54pbU.gif)\n",
        "\n",
        "For classification tasks, a good choice of gradient descent cost function is cross entropy loss which is defined as follows:\n",
        "\n",
        "$$ cross \\space entropy = \\frac{1}{N}\\sum_{y_i \\in Y} y_ilog(\\hat{y}_i) + (1-y_i)log(1-\\hat{y}_i)$$\n",
        "\n",
        "where $y_i$ are the real labels and $\\hat{y}_i$ are the corresponding predicted labels. Now lets write this out in code as well:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4eQ3lhRm90n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to compute the cross entropy between a model's output and the true labels\n",
        "def cross_entropy_cost(beta, X, y): \n",
        "    # evaluate the model for a given beta\n",
        "    log_func_v = logistic_regression_model(beta, X) \n",
        "    y = np.squeeze(y) \n",
        "    \n",
        "    # compute the cross entropy for each data point\n",
        "    step1 = y * np.log(log_func_v) \n",
        "    step2 = (1 - y) * np.log(1 - log_func_v) \n",
        "    final = -step1 -step2 \n",
        "\n",
        "    # return the average over all the data points\n",
        "    return np.mean(final) \n",
        "\n",
        "# Function to compute the gradients of the cost for each parameter -- don't worry too much about the math\n",
        "def partial_derivative(beta, X, y): \n",
        "    new_y = y.reshape(X.shape[0], -1) \n",
        "    first_calc = logistic_regression_model(beta, X) - new_y\n",
        "    final_calc = np.dot(first_calc.T, X) / len(X)\n",
        "    return final_calc \n",
        "\n",
        "# Finally lets put it all together to train with gradient descent\n",
        "def gradient_descent(X, y, learning_rate=1, minimum_change=.0001): \n",
        "\n",
        "    # Initialize model betas to 0 before starting training\n",
        "    beta = [0] * X.shape[1]\n",
        "    beta = np.matrix(beta)\n",
        "\n",
        "    # Compute our initial loss and initalize some variables\n",
        "    cost = cross_entropy_cost(beta, X, y) \n",
        "    change_in_cost = 1\n",
        "    num_iter = 1\n",
        "    \n",
        "    # If our loss is still changing enough from iteration to iteration\n",
        "    while(change_in_cost > minimum_change): \n",
        "        old_cost = cost \n",
        "\n",
        "        # Update the betas of our model using its gradient and compute the new cost\n",
        "        beta = beta - (learning_rate * partial_derivative(beta, X, y)) \n",
        "        cost = cross_entropy_cost(beta, X, y) \n",
        "        \n",
        "        # Check the change in cost so we know if we should stop training\n",
        "        change_in_cost = old_cost - cost \n",
        "\n",
        "        # Ocassionally print out some updates on the training\n",
        "        if num_iter % 1000 == 0:\n",
        "            print(f\"Iteration {num_iter}: {change_in_cost:.5f} change in cost.\")\n",
        "        num_iter += 1\n",
        "      \n",
        "    # Return the number of iterations spent training and the final betas\n",
        "    return np.array(beta).squeeze(), num_iter "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0PwI4UYvQmJ",
        "colab_type": "text"
      },
      "source": [
        "Before we run our model, let's also normalize our training data. When using gradient descent, we usually want to normalize our data before training. This helps with numerical stability (helps us avoid really small or really big numbers where the computer will have issues) and usually results in much quicker model convergence. An important point to note, however, is that it is very important to normalize your train and test data in the same way! For example, if you subtract the mean of you train data from all the train data points to normalize your train data to have mean 0, you should use should subtract that same value from the test data points (instead of using the test data mean)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWml-kuAP1Vm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generally, normalizing our data helps our model converge faster\n",
        "def normalize(column): \n",
        "    mins = min(column)\n",
        "    maxs = max(column)\n",
        "    column_range = maxs - mins \n",
        "    normalized = column / column_range\n",
        "    return normalized "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQFK9juvP1Vp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get our dataset\n",
        "X = bikeshare.loc[:, weather_features]\n",
        "X = pd.get_dummies(X)\n",
        "X = X.apply(normalize)\n",
        "y = bikeshare[\"high_traffic\"]\n",
        "\n",
        "# Move our data to numpy\n",
        "X = np.matrix(X)\n",
        "y = np.matrix(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gUFfT5H2-jZ",
        "colab_type": "text"
      },
      "source": [
        "Now that we have implemented everything we need to run a logstic regression model, lets run it on some data and see how it does!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "HgHLANlyP1Vs",
        "colab_type": "code",
        "outputId": "d7a7674f-9708-496e-c745-960b165a988f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Train our model, and save our beta values\n",
        "beta, num_iter = gradient_descent(X, y) \n",
        "\n",
        "print(\"Estimated regression coefficients:\", beta) \n",
        "print(\"No. of iterations:\", num_iter) \n",
        "\n",
        "# Use our model to make predictions for our data\n",
        "output_probabilities = logistic_regression_model(beta, X)\n",
        "output_probabilities = output_probabilities.tolist()[0]\n",
        "threshold = 0.5\n",
        "preds = [x > threshold for x in output_probabilities]\n",
        "\n",
        "# Print out some metrics based on our predictions\n",
        "y = np.array(y).squeeze()\n",
        "accuracy = 100*accuracy_score(y, preds)\n",
        "kappa = cohen_kappa_score(y, preds)\n",
        "precision = precision_score(y, preds)\n",
        "recall = recall_score(y, preds)\n",
        "print(f\"Accuracy: {accuracy:.1f} Kappa: {kappa:.3f} Precision: {precision:.3f} Recall: {recall:.3f}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1000: 0.00084 change in cost.\n",
            "Iteration 2000: 0.00019 change in cost.\n",
            "Iteration 3000: 0.00015 change in cost.\n",
            "Iteration 4000: 0.00012 change in cost.\n",
            "Iteration 5000: 0.00010 change in cost.\n",
            "Estimated regression coefficients: [ 0.18651935  1.99991752  2.77171851 -4.1097967   0.07498157]\n",
            "No. of iterations: 5053\n",
            "Accuracy: 70.8 Kappa: 0.415 Precision: 0.717 Recall: 0.685\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "td89PCouP1Vv",
        "colab_type": "code",
        "outputId": "d72dfd12-49f3-4570-8672-8c672be71eb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Prepare data to be plotted\n",
        "prob_series = pd.Series(output_probabilities)\n",
        "actual = pd.Series(bikeshare['high_traffic'])\n",
        "positives = prob_series.loc[actual == True]\n",
        "negatives = prob_series.loc[actual == False]\n",
        "\n",
        "# Set up plot\n",
        "ax.set_xticklabels([\"High Traffic\", \"Low Traffic\"])\n",
        "plt.ylabel(\"Predicted Probability of High Traffic\")\n",
        "plt.xlabel(\"Actual Label\")\n",
        "\n",
        "# Plot data\n",
        "plt.boxplot([positives, negatives], labels = ['positives', 'negatives'])\n",
        "ax = plt.gca()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdXg2Yh13Hu4",
        "colab_type": "text"
      },
      "source": [
        "Check out how the model mostly predicts higher values (above .5) when the actual label is True and mostly predicts lower values (below .5) when the actual label is False."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuzrlCfb2Kop",
        "colab_type": "text"
      },
      "source": [
        "## Logistic Regression with scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "OEmhwY_AP1Vz",
        "colab_type": "code",
        "outputId": "7597339d-c13b-4e46-c64d-d8d6e057ac2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Prepare data\n",
        "X = bikeshare.loc[:, weather_features]\n",
        "X = pd.get_dummies(X)\n",
        "y = bikeshare[\"high_traffic\"]\n",
        "\n",
        "# Train model\n",
        "classifier = LogisticRegression(penalty=\"none\", solver=\"lbfgs\", max_iter=10000, random_state=123)\n",
        "model = classifier.fit(X, y)\n",
        "\n",
        "# Get Predictions\n",
        "preds = model.predict(X)\n",
        "\n",
        "# Compute and print metrics\n",
        "accuracy = 100*accuracy_score(y, preds)\n",
        "kappa = cohen_kappa_score(y, preds)\n",
        "precision = precision_score(y, preds)\n",
        "recall = recall_score(y, preds)\n",
        "print(f\"Accuracy: {accuracy:.1f} Kappa: {kappa:.3f} Precision: {precision:.3f} Recall: {recall:.3f}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 70.8 Kappa: 0.415 Precision: 0.720 Recall: 0.678\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiYnT-3GP1V8",
        "colab_type": "text"
      },
      "source": [
        "## Comparisons Between Classification Algorithms\n",
        "\n",
        "Now that we have two completely different types of models, lets compare them and see which model is best for modeling this dataset!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaerh-WBP1V_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a function that takes in the predictions of a classifier, the true labels,\n",
        "# and a set of metrics and displays the model's performance on the metrics\n",
        "def common_evaluations(y_pred, y_actual, metrics, model_name = 'model'):\n",
        "    # Compute Metrics\n",
        "    conf_matrix = confusion_matrix(y_actual, y_pred)\n",
        "    model_results = {}\n",
        "    for (metric_name, metric) in metrics.items():\n",
        "        result = metric(y_actual, y_pred)\n",
        "        model_results[metric_name] = result\n",
        "\n",
        "    # Display Metrics\n",
        "    print(f\"Results for {model_name}:\")\n",
        "    ConfusionMatrixDisplay(conf_matrix, [\"low traffic\", \"high traffic\"]).plot(values_format='.4g')\n",
        "    plt.show()\n",
        "    print(model_results)\n",
        "    print(\"------------------------\")\n",
        "\n",
        "    return model_results\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVOJX5iwP1WD",
        "colab_type": "code",
        "outputId": "39174ec0-f108-4573-f73f-80477b1c7b36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        }
      },
      "source": [
        "# Set a list of classifiers we want to compare\n",
        "classifiers = {\n",
        "    \"Decision Tree\"      : DecisionTreeClassifier(criterion=\"entropy\", random_state=123),\n",
        "    \"Logistic Regression\": LogisticRegression(penalty=\"none\", solver=\"lbfgs\", max_iter=10000, random_state=123),\n",
        "}\n",
        "\n",
        "# Set a list of metrics we want to use to compare our classifiers \n",
        "metrics = {\n",
        "    \"Accuracy\" : lambda y,y_pred: 100*accuracy_score(y,y_pred),\n",
        "    \"Kappa\"    : cohen_kappa_score,\n",
        "    \"Precision\": precision_score,\n",
        "    \"Recall\"   : recall_score\n",
        "}\n",
        "\n",
        "# Choose a metric to optimize over\n",
        "metric_to_optimize = 'Accuracy'\n",
        "\n",
        "# Choose a subset of features for our dataset\n",
        "date_features = [\"day\", \"month\", \"year\", \"weekday\", \"season\", \"holiday\", \"workingday\"]\n",
        "time_features = [\"hour\"]\n",
        "weather_features = [\"weather\", \"temp\", \"atemp\", \"humidity\", \"windspeed\"]\n",
        "\n",
        "feature_set = date_features + time_features + weather_features\n",
        "\n",
        "# Create our train/test split using this subset of features\n",
        "X = bikeshare.loc[:, feature_set]\n",
        "y = bikeshare[\"high_traffic\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.20, random_state=12345)\n",
        "\n",
        "# Create variables to keep track of our best model and the metrics for each model\n",
        "best_model_metric = 0\n",
        "best_model_name = None\n",
        "\n",
        "all_model_metrics = {metric: [] for metric in metrics}\n",
        "\n",
        "# For each model in our set of classifiers\n",
        "for classifier_name, classifier in classifiers.items():\n",
        "\n",
        "    # Train the classifier and get its predictions on the test set\n",
        "    model = classifier.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Evaluate our metrics on the data \n",
        "    model_results = common_evaluations(y_pred, y_test, metrics, classifier_name)\n",
        "    \n",
        "    # Update our best model if this model is better than our previous best\n",
        "    comparison_metric = model_results[metric_to_optimize]\n",
        "    if comparison_metric > best_model_metric:\n",
        "        best_model_metric = comparison_metric\n",
        "        best_model_name = classifier_name\n",
        "\n",
        "    # Store the metrics for this model\n",
        "    for metric in model_results:\n",
        "        all_model_metrics[metric].append(model_results[metric]) \n",
        "    \n",
        "print(f\"Best classifier is: {best_model_name} \\nWith: {best_model_metric:.1f}% accuracy.\")   "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results for Decision Tree:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWkAAAEGCAYAAACn2WTBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "{'Accuracy': 91.3682277318641, 'Kappa': 0.827363535635805, 'Precision': 0.9108455882352942, 'Recall': 0.9158964879852126}\n",
            "------------------------\n",
            "Results for Logistic Regression:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWkAAAEGCAYAAACn2WTBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wH7OmHtVp4XyQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "{'Accuracy': 79.43067033976125, 'Kappa': 0.5885138246710199, 'Precision': 0.8024809160305344, 'Recall': 0.777264325323475}\n",
            "------------------------\n",
            "Best classifier is: Decision Tree \n",
            "With: 91.4% accuracy.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FRGny7tnwjc",
        "colab_type": "text"
      },
      "source": [
        "The code above is an example of good data science code. We are easily able to change and scale up our experiment with only minor modification. For example, we could easily change our set of classifiers, set of metrics, evaluation metric, and set of features to run new comparions. While it takes some practice to be able to write code like this, you will quickly find that this will reduce the time that it takes to set up a new experiment by orders of magnitudes and that it results in code that is much more concise and easy to read!\n",
        "\n",
        "Before we conclude this section, lets make a plot to visualize the difference in precision and recall between our two models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab_type": "code",
        "id": "O6I66E2Uayp6",
        "outputId": "037d5b65-775b-4be4-c5d6-0645f6af696a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# Set up plot\n",
        "plt.xlim(0.5,1)\n",
        "plt.xlabel(\"Precision\")\n",
        "plt.ylim(0.5,1)\n",
        "plt.ylabel(\"Recall\")\n",
        "plt.title(\"Recall vs Precision for Different Classifiers\")\n",
        "\n",
        "# Plot data\n",
        "names = list(classifiers.keys())\n",
        "for i in range(len(classifiers)):\n",
        "    x = all_model_metrics['Precision'][i]\n",
        "    y = all_model_metrics['Recall'][i]\n",
        "    plt.scatter(x, y)\n",
        "    plt.text(x+.01, y+.01, names[i], fontsize=9)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbCzzgPLpdTP",
        "colab_type": "text"
      },
      "source": [
        "For this dataset, we can see that decision trees blow logistic regression out of the water since we get much better precision and recall with them. While, at first, it may seem like the only to figure this out would be to train and evaluate both of the models, we actually could have figured this out just by considering the properties of the two models and our data! Let's think about how we could have done that.\n",
        "\n",
        "From our experiments with trees, we know that date and time are strong predictors of bikeshare traffic level. The question is, why is logistic regression not able to use this data effectively? The answer is actually pretty simple. The numerical ordering for date and time don't make sense. For example, December and January are very close together. In contrast, when we look at our data, January and December are actually really far apart because they are Month 1 and Month 12 respectively! Furthermore, the same thing thing happens when we look at the time of day or day of the week!\n",
        "\n",
        "When we use decision trees, we can draw multiple lines between months to use in our classification, but with logistic regression we can only draw one. This means that for logistic regression, there is no way to make up for this discrepancy between the true cyclical structure of the months and their ordered representation in our dataset. The problem is not the model, but the format of the data (oops!). This is an awesome example of how data format influences model choice and model choice influences data format!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qr7DM2ozP1WP",
        "colab_type": "text"
      },
      "source": [
        "# Tomorrow\n",
        "Tomorrow, we'll dive into much more detail on experimental setup and the type of tuning and evaluation that you can do once you have multiple classifiers, feature sets, and other aspects of classification to tune."
      ]
    }
  ]
}